---
title: "Trend analysis using survey data"
author: "Luis E Segura"
date: "2023-05-20"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(here)
```

### Step 1: Load Packages and Dataset
We will be using four packages in this session. 

The package tidyverse is a collection of packages designed for data science. All packages included in tidyverse share an underlying coding grammar often called tidy. You can learn more about coding using tidy language in the book R for Data Science by Hadley Wickham. An online version can be found here: https://r4ds.hadley.nz

The package survey is an R package that provides functions to analyze data from complex surveys. Documentation for this package can be found here: https://r-survey.r-forge.r-project.org/survey/

The package srvyr allows to use tidy coding language using functions from the package survey. You can read more about this here: http://gdfe.co/srvyr/ 

The package broom takes the messy output of built-in functions in R, such as lm, nls, or t.test, and turns them into tidy tibbles. You can read more about this package here: https://cran.r-project.org/web/packages/broom/vignettes/broom.html

The dataset we are going to use to replicate analyses done in Martins et. al. 2015 (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4447574/) comes from the National Survey on Drug Use and Health (NSDUH). We provide a version of the NSDUH ready for analysis here: https://www.dropbox.com/home/Survey%20Workshop/2022/Data 

```{r load packages, echo = T}
### Load libraries needed
library(tidyverse)
library(survey)
library(srvyr)
library(broom)
library(skimr)

```

You can either store the dataset in the local drive of your computer or you can load it directly from cloud-based repositories. In this case, we are going to load it directly from dropbox. In order to do this, first copy the dropbox link for the dataset (https://www.dropbox.com/s/8vsczx1aevnsags/nsduh_ready4analysis.RData?dl=0). Make sure you change the last part of this link dl=0 to dl=1. Use the function url() to tell R that you are reading from a web link and the function load(), to read in .RData files into R.
```{r load data, echo = T}
load(url("https://www.dropbox.com/s/8vsczx1aevnsags/nsduh_ready4analysis.RData?dl=1")) 

```

### Step 2: Data Recoding
It is very important to do all of your recoding before creating your survey design. 

Any changes to the data done after creating the survey design object will not be recognized by the survey design object.

```{r recode, echo = T}
nsduh <- nsduh |>
  ### creating a continuous indicator of year (1, 2, 3, 4, 5, ... n) that corresponds to 2002 - 2011
  mutate(year_num = ifelse(year < 2008, year - 2001, year - 2003),
         ### creating a factor version of the year indicator to later use in our graphs
         year_fct = factor(year_num, labels = c("2002", "2003", "2004", "2005", 
                                                "2008", "2009", "2010", "2011")),
         ### creating a numeric version of our previously recoded heroin use variable
         heryr_num = ifelse(heryr_r == "No PY use", 0, 
                             ifelse(heryr_r == "Any PY use", 1, heryr_r))) 
```

### Step 4: Create a survey design object

Since we are using complex survey data, we need to specify the survey design object. 

This object contains all the data and meta-data needed for analysis.

The main arguments to the survey design function are:
1) "id" to specify sampling units (PSUs and optionally later stages),
2) "strata" to specify strata,
3) "weights" to specify sampling weights
```{r survey design, echo = T}
nsduh_design <-
  nsduh |> 
  as_survey_design(id = verep, ### PSU - first stage cluster sampling
                   strata = vestr, ### strata
                   weights = wt_new, ### sampling weight
                   nest = TRUE ### clusters nested within strata
  )

nsduh_design
```

### Step 5: Descriptive Analysis and Graphs of Trends
In this example, we are interested in calculating the prevalence of heroin per year. Prevalences will be estimated per 1000 individuals.
```{r heroin year, echo = T}
yearly_heroin <- nsduh_design |>
  group_by(year_fct) |>
  ### estimating prevalences per 1000
  summarise(prevalence = survey_mean(heryr_num, na.rm = T, vartype = "ci") * 1000) 

yearly_heroin
```

We are going to visually inspect if there is an apparent trend over time of past year heroin use. 

We plot the annual proportion of heroin use per 1000
```{r plot, echo = T}
yearly_heroin |> 
  ### tell ggplot what is your x and y axis and the lower and upper CI. group is set to 1 because all points are grouped in time.
  ggplot(aes(x = year_fct, y = prevalence, ymin = prevalence_low, ymax = prevalence_upp, group = 1)) + 
  geom_line() + 
  ### point shapes here: http://www.sthda.com/english/wiki/ggplot2-point-shapes 
  geom_point(shape = 17, size = 2) + 
  ### draw a shaded area (ribbon) that represents the confidence interval (confidence band)
  geom_ribbon(alpha = 0.1) + 
   ### title of y axis
  ylab("Proportion of Heroin use per 1000") +
  xlab("year") +
  ### setting a theme. There are multiple packages for custom graph themes like "cowplot" and "ggthemes".
  theme_classic()  
```

We can see that there seems to be somewhat of a trend over time in past year heroin use. 

From this graph, we can observe that the trend is not perfectly linear.

We can add to the same graph a linear prediction
```{r plot2, echo = T}
yearly_heroin |>
  ggplot(aes(x = year_fct, y = prevalence, ymin = prevalence_low, ymax = prevalence_upp, group = 1)) + 
  geom_line() + 
  geom_point(shape = 17, size = 2) + 
  ### add a linear fit line 
  geom_smooth(method = "lm") + 
  ylab("Proportion of Heroin use per 1000") + 
  xlab("year") +
  theme_classic()
```

Or a apply some transformations like a smooth line over the data and see if this fits better
```{r plot3, echo = T}
yearly_heroin |>
  ggplot(aes(x = year_fct, y = prevalence, ymin = prevalence_low, ymax = prevalence_upp, group = 1)) + 
  geom_point(shape = 17, size = 2) + 
  ### add a polynomial line. See ?geom_smooth for more options
  geom_smooth(method = "loess") + 
  ylab("Proportion of Heroin use per 1000") + 
  xlab("year") +
  theme_classic()
```

### Step 5: Testing trends over time
Is there evidence of a significant (p-trend) increase/decrease of past year heroin use per unit of time?
If outcome is continuous use a linear regression and include year as a continuous predictor
If outcome is binary use a logistic regression and include year as a continuous predictor

In our case, past year heroin use is a binary variable (0/1), so we will assess if there is a trend over time by fitting a logistic regression model with year as a continuous predictor.
If the coefficient for year (as a continuous variable) is significant (p-value < 0.05), then there is evidence of a trend over time. 
The sign of the coefficient (positive or negative), tells us whether this is an increasing or decreasing (positive or negative) trend.
```{r trend, echo = T}
svyglm(heryr_r ~ year_num, design = nsduh_design, family = binomial(link = "logit")) |>
  tidy()

```

If you get this warning message:
Warning message:
In eval(family$initialize) : non-integer #successes in a binomial glm!

Do not worry. Glm is just picky when it comes to specifying binomial (and Poisson) models.
It warns if it detects that the number of trials or successes is non-integral, but it goes ahead and fits the model anyway.
If you want to suppress the warning (and you're sure it's not a problem), use family = quasibinomial(link = "logit") instead.

#### Does heroin use increase compared to 2002?
Here we are going to use year as a factor and compute the contrast between heroin use in year i vs 2002, where i equals to all the years available (2002, 2003, 2004, 2005, 2008, 2009, 2010, 2011). For example, one contrast would be heroin use in 2003 vs 2002, heroin use in 2005 vs 2002, etc. 

Use the variable year_fct
```{r trend2, echo = T}
svyglm(heryr_r ~ year_fct, design = nsduh_design, family = binomial(link = "logit")) |>
  tidy(conf.int = T, exponentiate = T)
```

the betas from rows 2 to 8 are Odds Ratios (ORs) omparing year i vs 2002. For example, row 2 shows the OR (0.805) of heroin use comparing year 2003 vs 2002. 
This means that the odds of of past year heroin use decreased in 2003 compared to 2002. 
Row 8 shows the OR (1.48) of heroin use comparing year 2011 vs 2002. The odds of past year heroin use increased 48% in 2011 compared to 2002.

####  Are the trends the same by race?
Now we are going to calculate the prevalence per 1000 individuals of heroin use per year by race/ethnic group.
```{r trend race, echo = T}
race_heroin_year <- nsduh_design |> 
  group_by(race, year_fct) |>
  summarise(prevalence = survey_mean(heryr_num, na.rm = T, vartype = "ci") * 1000)

race_heroin_year
```

Plot the results using a smooth line.
```{r trend race plot, echo = T}

race_heroin_year |>
  ### tell ggplot what is your x and y axis and the lower and upper CI. adding race as the variable that defines grouping, line type and shape of points.
  ggplot( aes(x = year_fct, y = prevalence, group = race, linetype = race, shape = race, color = race)) + 
  geom_smooth(se = F) +
  geom_point(size = 2) +
  ylab("Proportion of Heroin use per 1000") + 
  xlab("year") +
  theme_classic() 
```

#### Testing for a linear trend
Is there evidence of a significant (p-trend) increase/decrease of past year heroin use per unit of time for each race/ethnic group?

Our outcome is binary so we will use logistic regression and include year as a continuous predictor. 

We are going to fit 4 models for each race/ethnic category using a loop. 
```{r test trend race, echo = T}
### race/ethnic group levels
race_levels <- levels(nsduh$race)

### create an empty list to store results
results_list <- list()

### The loop. For each level of race in race_levels
for(i in race_levels){
  
  ### create a subset of the survey design object filtered by a specific race level
  design_subset <- nsduh_design |> filter(race == i)
  
  ### fit the logistic model to that specific race level using the design_subset
  model <- svyglm(heryr_r ~ year_num, design = design_subset, family = binomial(link = "logit")) |>
    tidy(exponentiate = T, conf.int = T)
  
  ### store the model results in results_list. 
  results_list[[i]] <- model |>
    ### Filter the model results to only the coefficient of year_num (year as continuous)
    filter(term == "year_num") |>
    ### select only this columns
    select(term, estimate, p.value, conf.low, conf.high) |>
    ### create a variable called race
    mutate(race = i) |>
    ### relocate race before term
    relocate(race, .before = term)
  
}

### coerce list into a dataframe
results_list %>%
  bind_rows()

```

These results show that the odds of past year heroin use among whites significantly increased 1.13 times per year (p-trend = 0.00000928).
The odds of past year heroin use among Black individuals decrease 0.967 times per year, but the trend was not significant (p-trend = 0.685).
The odds of past year heroin use among Hispanics increased 1.07 times per year, but the trend was not significant (p-trend = 0.257).
The odds of past year heroin use among individuals of Other race/ethnic groups increased 1.02 times per year, but the trend was not significant (p-trend = 0.811).

